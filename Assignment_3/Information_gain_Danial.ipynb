{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danialebrat/Comp_8740/blob/master/Assignment_3/Information_gain_Danial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cba1b7",
      "metadata": {
        "id": "06cba1b7"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UzxPESAHwGa0",
        "outputId": "372d548d-a084-43f3-b761-ebdeca59ae87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UzxPESAHwGa0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn_evaluation"
      ],
      "metadata": {
        "id": "qkRhITppdMvo"
      },
      "id": "qkRhITppdMvo",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c025922b",
      "metadata": {
        "id": "c025922b"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.feature_selection import chi2, SelectPercentile, mutual_info_classif\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn_evaluation.plot import grid_search\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant variables\n",
        "\n",
        "DATASET = \"/content/drive/MyDrive/Dataset/COMP_8740/Breastcancer.csv\"\n",
        "\n",
        "PLOT_PATH = \"/content/drive/MyDrive/Colab Notebooks/COMP_8740/Assignmet3/Plots/\"\n",
        "\n",
        "RESULT_PATH = \"/content/drive/MyDrive/Colab Notebooks/COMP_8740/Assignmet3/Results/\""
      ],
      "metadata": {
        "id": "Y1nUNAgL8m2I"
      },
      "id": "Y1nUNAgL8m2I",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ML_Methods:\n",
        "\n",
        "    def __init__(self, name, dataset):\n",
        "        self.name = name\n",
        "        self.dataset = dataset\n",
        "\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        \"\"\"\n",
        "        create x and y from a pandas dataframe\n",
        "        x, which are 2D point will be scaled using min-max scaler\n",
        "        :param dataframe:\n",
        "        :return (Scaled X (minmax), y):\n",
        "        \"\"\"\n",
        "\n",
        "        X = df.iloc[:, :-1].values\n",
        "        y = df.iloc[:, -1].values\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        x = scaler.fit_transform(X)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def adding_methods(self):\n",
        "        \"\"\"\n",
        "        adding all the methods with their specific names in a list\n",
        "        :return: a List containing tuple of models (name of the model, model)\n",
        "        \"\"\"\n",
        "\n",
        "        Models = []\n",
        "\n",
        "        # models\n",
        "        # Models.append(self.SVM_rbf())\n",
        "        Models.append(self.Random_Forest())\n",
        "        # Models.append(self.Deep_Neural_Network())\n",
        "\n",
        "        return Models\n",
        "\n",
        "\n",
        "    def Kfold_report(self, Models, x_train, y_train, dataset_name):\n",
        "        \"\"\"\n",
        "        training all the models from the list of models using 10 fold cross validation\n",
        "        :param x_train:\n",
        "        :param y_train:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"**********\")\n",
        "        print(\"{} Dataset Results: \".format(dataset_name))\n",
        "\n",
        "        results = []\n",
        "        method_names = []\n",
        "        for name, model in Models:\n",
        "            # train the models\n",
        "            KFold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "            CrossValidation = cross_val_score(model, x_train, y_train, cv=KFold, scoring='accuracy')\n",
        "            results.append(CrossValidation)\n",
        "            method_names.append(name)\n",
        "            print(f\"{name} Training Accuracy : {CrossValidation.mean()*100:.2f}%\")\n",
        "\n",
        "        return results, method_names\n",
        "\n",
        "\n",
        "    def training_models(self, Models, x_train, x_test, y_train, y_test, datasetname):\n",
        "\n",
        "        Results = []\n",
        "        for name, model in Models:\n",
        "            model.fit(x_train, y_train)\n",
        "            predicted = model.predict(x_test)\n",
        "            cm = confusion_matrix(y_test, predicted)\n",
        "            AS = accuracy_score(y_test, predicted)\n",
        "\n",
        "            Classifier, PPV, NPV, Sensitivity, Specificity, Testing_Accuracy = self.confusion_metrics(cm, AS, name, datasetname)\n",
        "\n",
        "            Results.append([Classifier,\n",
        "                            PPV,\n",
        "                            NPV,\n",
        "                            Sensitivity,\n",
        "                            Specificity,\n",
        "                            Testing_Accuracy])\n",
        "\n",
        "        # Storing the result\n",
        "        self.storing_results(Results, datasetname)\n",
        "\n",
        "\n",
        "    def Random_Forest(self):\n",
        "        \"\"\"\n",
        "        create a Random_Forest classifier\n",
        "        :return (name of the mode, Random_Forest model):\n",
        "        \"\"\"\n",
        "        name = \"Random_Forest\"\n",
        "        RF_Model = RandomForestClassifier()\n",
        "        return (name, RF_Model)\n",
        "\n",
        "    \n",
        "    def SVM_rbf(self):\n",
        "      \"\"\"\n",
        "      create a SVM classifier\n",
        "      :return (name of the mode, QDA model):\n",
        "      \"\"\"\n",
        "      name = \"SVM_rbf\"\n",
        "      SVM_rbf_model = SVC(kernel = 'rbf', random_state = 42)\n",
        "      return(name, SVM_rbf_model)\n",
        "\n",
        "\n",
        "    def Keras_Deep_Neural_Network(self):\n",
        "        \"\"\"\n",
        "        create a Deep_Neural_Network classifier\n",
        "        \"\"\"\n",
        "\n",
        "        DNN_model = Sequential()\n",
        "\n",
        "        DNN_model.add(Dense(64, activation='relu', input_dim=204))\n",
        "        DNN_model.add(Dropout(0.1))\n",
        "        DNN_model.add(Dense(32, activation='relu'))\n",
        "        DNN_model.add(Dropout(0.2))\n",
        "        DNN_model.add(Dense(16, activation='relu'))\n",
        "        DNN_model.add(Dropout(0.2))\n",
        "        DNN_model.add(Dense(32, activation='relu'))\n",
        "        DNN_model.add(Dropout(0.2))\n",
        "        DNN_model.add(Dense(64, activation='relu'))\n",
        "        DNN_model.add(Dropout(0.3))\n",
        "\n",
        "        DNN_model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "        DNN_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return DNN_model\n",
        "\n",
        "\n",
        "    def Deep_Neural_Network(self):\n",
        "        \"\"\"\n",
        "        create a Deep_Neural_Network classifier\n",
        "        :return (name of the mode, Deep_Neural_Network model):\n",
        "        \"\"\"\n",
        "        name = \"Deep_Neural_Network\"\n",
        "\n",
        "        # Wrap Keras model so it can be used by scikit-learn\n",
        "        model = KerasClassifier(build_fn=self.Keras_Deep_Neural_Network,\n",
        "                                epochs=20,\n",
        "                                batch_size=16,\n",
        "                                verbose=0)\n",
        "\n",
        "        return (name, model)\n",
        "\n",
        "\n",
        "\n",
        "    def data_spliting(self, x, y, test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Split the data into x_train, x_test, y_train, y_test\n",
        "        :param x: x (data)\n",
        "        :param y: y (labels)\n",
        "        :param test_size: size of test dataset\n",
        "        :param random_state: 1 or 0\n",
        "        :return: x_train, x_test, y_train, y_test\n",
        "        \"\"\"\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "    def plotting(self, results, names, dataset_name):\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        boxplot = plt.boxplot(results, patch_artist=True, labels=names)\n",
        "\n",
        "\n",
        "        # fill with colors\n",
        "        colors = ['pink', 'lightblue', 'lightgreen', 'lime', 'grey']\n",
        "        for box, color in zip(boxplot['boxes'], colors):\n",
        "            box.set(color=color)\n",
        "\n",
        "        title = \"Classifiers Comparison _ {}\".format(dataset_name)\n",
        "        plt.title(title)\n",
        "\n",
        "        # saving the plots\n",
        "        fname = PLOT_PATH + title + \".png\"\n",
        "        plt.savefig(fname, dpi=100)\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "    def confusion_metrics(self, cm, accuracy_score, method_name, dataset_name):\n",
        "\n",
        "        FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "        FN = cm.sum(axis=1) - np.diag(cm)\n",
        "        TP = np.diag(cm)\n",
        "        TN = cm.sum() - (FP + FN + TP)\n",
        " \n",
        "        # Sensitivity, hit rate, recall, or true positive rate\n",
        "        TPR = TP/(TP+FN)\n",
        "        # Specificity or true negative rate\n",
        "        TNR = TN/(TN+FP) \n",
        "        # Precision or positive predictive value\n",
        "        PPV = TP/(TP+FP)\n",
        "        # Negative predictive value\n",
        "        NPV = TN/(TN+FN)\n",
        "        # Fall out or false positive rate\n",
        "        FPR = FP/(FP+TN)\n",
        "        # False negative rate\n",
        "        FNR = FN/(TP+FN)\n",
        "        # False discovery rate\n",
        "        FDR = FP/(TP+FP)\n",
        "\n",
        "        # Overall accuracy\n",
        "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "        avg_PPV  = np.average(PPV, axis=None, weights=None, returned=False)\n",
        "        avg_NPV  = np.average(NPV, axis=None, weights=None, returned=False)\n",
        "        avg_TPR  = np.average(TPR, axis=None, weights=None, returned=False)\n",
        "        avg_TNR  = np.average(TNR, axis=None, weights=None, returned=False)\n",
        "        avg_ACC  = np.average(ACC, axis=None, weights=None, returned=False)\n",
        "\n",
        "        # Accuracy for test set\n",
        "        accuracy = round(accuracy_score*100, 2)\n",
        "\n",
        "        print(\"**************\")\n",
        "        print(\"Classifier: {} _ Dataset: {}\".format(method_name, dataset_name))\n",
        "        print(\"PPV:{:.2f} | NPV:{:.2f} | Sensitivity:{:.2f} | Specificity:{:.2f} | Total_Accuracy:{:.2f}\".format(avg_PPV, avg_NPV, avg_TPR, avg_TNR, avg_ACC))\n",
        "        print(\"Accuracy Score for test_set: {:.2f} \".format(accuracy))\n",
        "\n",
        "        return method_name, avg_PPV, avg_NPV, avg_TPR, avg_TNR, accuracy\n",
        "\n",
        "\n",
        "    def storing_results(self, Results , dataset_name):\n",
        "        \"\"\"\n",
        "        Storing the results in a csv file\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        info = pd.DataFrame(Results, columns=['Classifier', 'PPV', 'NPV', 'Sensitivity', 'Specificity','Testing_Accuracy'])\n",
        "        self.store(info, dest=RESULT_PATH, name=dataset_name)\n",
        "\n",
        "\n",
        "    def store(self, df, dest, name):\n",
        "        \"\"\"\n",
        "        Storing the results as an excel file in a folder\n",
        "        :param dest:\n",
        "        :param name:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        path = dest + name + \".xlsx\"\n",
        "        df.to_excel(path)"
      ],
      "metadata": {
        "id": "OHin6fH77ZOT"
      },
      "id": "OHin6fH77ZOT",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(file):\n",
        "  # read dataset csv as a Dataframe\n",
        "  df = pd.read_csv(file)\n",
        "  return df"
      ],
      "metadata": {
        "id": "s4JBooSR7Q7B"
      },
      "id": "s4JBooSR7Q7B",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_tuning(Models, x_train, y_train):\n",
        "\n",
        "  for name, model in Models:\n",
        "    if name == \"SVM_rbf\":\n",
        "      \n",
        "      continue\n",
        "      # C_range = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "      # gamma_range = [0.02,0.05, 0.07, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "      # degrees = range(3, 10)\n",
        "      # parameters = dict(gamma=gamma_range, C=C_range, degree=degrees)\n",
        "\n",
        "    else:\n",
        "      parameters = {\n",
        "          'max_features' : [7, 8, 9, 10, 12, 13],\n",
        "          'n_estimators': [250, 300, 350, 400, 450, 500],\n",
        "          }\n",
        "\n",
        "\n",
        "    grid = GridSearchCV(model, parameters, refit = True, verbose = 0)\n",
        "  \n",
        "    # fitting the model for grid search\n",
        "    grid.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "    gs = GridSearchCV(estimator = model,\n",
        "                              param_grid = parameters,\n",
        "                              scoring = 'accuracy',\n",
        "                              cv = 10,\n",
        "                              refit = True,\n",
        "                              n_jobs = -1,\n",
        "                              verbose = 0)\n",
        "    \n",
        "    gs.fit(x_train, y_train)\n",
        "\n",
        "    results = pd.DataFrame(gs.cv_results_)\n",
        "    display(results)\n",
        "\n",
        "    grid_search(gs.cv_results_, change='max_features')\n",
        "    plt.show()\n",
        "\n",
        "    best_accuracy = gs.best_score_\n",
        "    best_parameters = gs.best_params_\n",
        "\n",
        "    print(\"{} Classifies: ***** \".format(name))\n",
        "    print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
        "    print(\"Best Parameters:\", best_parameters)"
      ],
      "metadata": {
        "id": "A2gXqZocJJN2"
      },
      "id": "A2gXqZocJJN2",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection_Information_gain(x, y):\n",
        "\n",
        "  scores = mutual_info_classif(x,y)\n",
        "  \n",
        "  # p_values = pd.Series(scores)\n",
        "  # p_values.sort_values(ascending = False , inplace = True)\n",
        "  # p_values.plot.bar()\n",
        "  # plt.show()\n",
        "\n",
        "  X_new = SelectPercentile(mutual_info_classif, percentile=1).fit_transform(x, y)\n",
        "\n",
        "  return X_new\n"
      ],
      "metadata": {
        "id": "98vgd2zOIUgS"
      },
      "id": "98vgd2zOIUgS",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection_ChiSquare(x, y):\n",
        "\n",
        "  scores = chi2(x,y)\n",
        "  \n",
        "  # p_values = pd.Series(scores)\n",
        "  # p_values.sort_values(ascending = False , inplace = True)\n",
        "  # p_values.plot.bar()\n",
        "  # plt.show()\n",
        "\n",
        "  X_new = SelectPercentile(chi2, percentile=70).fit_transform(x, y)\n",
        "\n",
        "  return X_new"
      ],
      "metadata": {
        "id": "dGWE4BJ_8XD7"
      },
      "id": "dGWE4BJ_8XD7",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    name = \"Breast Cancer\"\n",
        "\n",
        "    # reading the data\n",
        "    Data = read_csv(DATASET)\n",
        "    \n",
        "    # creating and ML_method object for the dataset\n",
        "    method = ML_Methods(name=\"BreastCancer\", dataset=Data)\n",
        "    X, y = method.preprocess(Data)\n",
        "\n",
        "    # Applying feature selection\n",
        "    x_filtering  = feature_selection_ChiSquare(X, y)\n",
        "    x  = feature_selection_Information_gain(x_filtering, y)\n",
        "\n",
        "    print('Original number of features:', X.shape)\n",
        "    print('Reduced number of features:', x.shape)\n",
        "\n",
        "    \n",
        "\n",
        "    # spliting the dataset\n",
        "    x_train, x_test, y_train, y_test = method.data_spliting(x, y)\n",
        "\n",
        "    # Adding methods:\n",
        "    Models = method.adding_methods()\n",
        "\n",
        "    # train the models and getting the results\n",
        "    results, method_name = method.Kfold_report(Models, x_train, y_train, name)\n",
        "\n",
        "    method.plotting(results, method_name, name)\n",
        "\n",
        "    method.training_models(Models, x_train, x_test, y_train, y_test, name)\n",
        "\n",
        "\n",
        "    print(\"******************************\")\n",
        "\n",
        "\n",
        "    grid_search_tuning(Models, x_train, y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_pVD1f0gAjdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc4340a8-4047-44fe-93f5-57825d798185"
      },
      "id": "_pVD1f0gAjdc",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: (158, 13582)\n",
            "Reduced number of features: (158, 96)\n",
            "**********\n",
            "Breast Cancer Dataset Results: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_Forest Training Accuracy : 87.24%\n",
            "**************\n",
            "Classifier: Random_Forest _ Dataset: Breast Cancer\n",
            "PPV:0.84 | NPV:0.97 | Sensitivity:0.88 | Specificity:0.97 | Total_Accuracy:0.95\n",
            "Accuracy Score for test_set: 87.50 \n",
            "******************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0        0.591937      0.017445         0.046260        0.005457   \n",
              "1        0.699852      0.017520         0.052870        0.001585   \n",
              "2        0.810102      0.011763         0.063593        0.005858   \n",
              "3        0.935931      0.011581         0.070276        0.002607   \n",
              "4        1.042114      0.012556         0.079592        0.005098   \n",
              "5        1.159430      0.015995         0.087570        0.002998   \n",
              "6        0.586941      0.010723         0.044078        0.001365   \n",
              "7        0.714026      0.021589         0.054775        0.004172   \n",
              "8        0.830452      0.011814         0.066262        0.011771   \n",
              "9        0.950566      0.021602         0.069221        0.002092   \n",
              "10       1.057002      0.013511         0.077877        0.002779   \n",
              "11       1.175970      0.015584         0.087078        0.006253   \n",
              "12       0.598533      0.012657         0.046022        0.006510   \n",
              "13       0.717412      0.018444         0.053233        0.005345   \n",
              "14       0.840146      0.017874         0.059204        0.001202   \n",
              "15       0.952790      0.015310         0.067231        0.000706   \n",
              "16       1.073415      0.025781         0.084002        0.016585   \n",
              "17       1.201793      0.029176         0.084818        0.001554   \n",
              "18       0.604089      0.011328         0.045774        0.006544   \n",
              "19       0.725539      0.011654         0.051192        0.002337   \n",
              "20       0.849230      0.012535         0.060575        0.005969   \n",
              "21       0.968342      0.014383         0.068884        0.002275   \n",
              "22       1.092851      0.019991         0.076586        0.001639   \n",
              "23       1.208295      0.023697         0.085552        0.003687   \n",
              "24       0.626611      0.012661         0.044301        0.002368   \n",
              "25       0.737643      0.010097         0.055498        0.007288   \n",
              "26       0.874947      0.024648         0.061748        0.002047   \n",
              "27       0.981211      0.009460         0.067340        0.001616   \n",
              "28       1.115720      0.020121         0.075922        0.001822   \n",
              "29       1.231444      0.012711         0.085046        0.002589   \n",
              "30       0.630603      0.009662         0.042459        0.001643   \n",
              "31       0.752881      0.011100         0.050644        0.000690   \n",
              "32       0.882052      0.015311         0.058209        0.001247   \n",
              "33       1.012536      0.018729         0.069874        0.004926   \n",
              "34       1.584637      0.402313         0.097955        0.030593   \n",
              "35       1.249749      0.027702         0.085544        0.017387   \n",
              "\n",
              "   param_max_features param_n_estimators  \\\n",
              "0                   7                250   \n",
              "1                   7                300   \n",
              "2                   7                350   \n",
              "3                   7                400   \n",
              "4                   7                450   \n",
              "5                   7                500   \n",
              "6                   8                250   \n",
              "7                   8                300   \n",
              "8                   8                350   \n",
              "9                   8                400   \n",
              "10                  8                450   \n",
              "11                  8                500   \n",
              "12                  9                250   \n",
              "13                  9                300   \n",
              "14                  9                350   \n",
              "15                  9                400   \n",
              "16                  9                450   \n",
              "17                  9                500   \n",
              "18                 10                250   \n",
              "19                 10                300   \n",
              "20                 10                350   \n",
              "21                 10                400   \n",
              "22                 10                450   \n",
              "23                 10                500   \n",
              "24                 12                250   \n",
              "25                 12                300   \n",
              "26                 12                350   \n",
              "27                 12                400   \n",
              "28                 12                450   \n",
              "29                 12                500   \n",
              "30                 13                250   \n",
              "31                 13                300   \n",
              "32                 13                350   \n",
              "33                 13                400   \n",
              "34                 13                450   \n",
              "35                 13                500   \n",
              "\n",
              "                                       params  split0_test_score  \\\n",
              "0    {'max_features': 7, 'n_estimators': 250}           0.769231   \n",
              "1    {'max_features': 7, 'n_estimators': 300}           0.846154   \n",
              "2    {'max_features': 7, 'n_estimators': 350}           0.846154   \n",
              "3    {'max_features': 7, 'n_estimators': 400}           0.923077   \n",
              "4    {'max_features': 7, 'n_estimators': 450}           0.846154   \n",
              "5    {'max_features': 7, 'n_estimators': 500}           0.923077   \n",
              "6    {'max_features': 8, 'n_estimators': 250}           0.923077   \n",
              "7    {'max_features': 8, 'n_estimators': 300}           0.769231   \n",
              "8    {'max_features': 8, 'n_estimators': 350}           0.846154   \n",
              "9    {'max_features': 8, 'n_estimators': 400}           0.923077   \n",
              "10   {'max_features': 8, 'n_estimators': 450}           0.846154   \n",
              "11   {'max_features': 8, 'n_estimators': 500}           0.846154   \n",
              "12   {'max_features': 9, 'n_estimators': 250}           0.923077   \n",
              "13   {'max_features': 9, 'n_estimators': 300}           0.846154   \n",
              "14   {'max_features': 9, 'n_estimators': 350}           0.846154   \n",
              "15   {'max_features': 9, 'n_estimators': 400}           0.846154   \n",
              "16   {'max_features': 9, 'n_estimators': 450}           0.923077   \n",
              "17   {'max_features': 9, 'n_estimators': 500}           0.846154   \n",
              "18  {'max_features': 10, 'n_estimators': 250}           0.846154   \n",
              "19  {'max_features': 10, 'n_estimators': 300}           0.846154   \n",
              "20  {'max_features': 10, 'n_estimators': 350}           0.846154   \n",
              "21  {'max_features': 10, 'n_estimators': 400}           0.846154   \n",
              "22  {'max_features': 10, 'n_estimators': 450}           0.846154   \n",
              "23  {'max_features': 10, 'n_estimators': 500}           0.846154   \n",
              "24  {'max_features': 12, 'n_estimators': 250}           0.846154   \n",
              "25  {'max_features': 12, 'n_estimators': 300}           0.923077   \n",
              "26  {'max_features': 12, 'n_estimators': 350}           0.846154   \n",
              "27  {'max_features': 12, 'n_estimators': 400}           0.846154   \n",
              "28  {'max_features': 12, 'n_estimators': 450}           0.846154   \n",
              "29  {'max_features': 12, 'n_estimators': 500}           0.846154   \n",
              "30  {'max_features': 13, 'n_estimators': 250}           0.846154   \n",
              "31  {'max_features': 13, 'n_estimators': 300}           0.923077   \n",
              "32  {'max_features': 13, 'n_estimators': 350}           0.846154   \n",
              "33  {'max_features': 13, 'n_estimators': 400}           0.923077   \n",
              "34  {'max_features': 13, 'n_estimators': 450}           0.846154   \n",
              "35  {'max_features': 13, 'n_estimators': 500}           0.846154   \n",
              "\n",
              "    split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0            0.846154           0.923077           0.923077   \n",
              "1            0.769231           1.000000           1.000000   \n",
              "2            0.769231           1.000000           0.923077   \n",
              "3            0.769231           0.923077           1.000000   \n",
              "4            0.769231           1.000000           1.000000   \n",
              "5            0.769231           1.000000           0.923077   \n",
              "6            0.769231           0.923077           0.923077   \n",
              "7            0.769231           1.000000           0.923077   \n",
              "8            0.769231           0.923077           1.000000   \n",
              "9            0.769231           1.000000           0.923077   \n",
              "10           0.769231           1.000000           0.923077   \n",
              "11           0.769231           0.923077           1.000000   \n",
              "12           0.769231           0.923077           0.923077   \n",
              "13           0.769231           0.846154           0.923077   \n",
              "14           0.769231           1.000000           0.923077   \n",
              "15           0.769231           0.923077           0.923077   \n",
              "16           0.769231           0.923077           0.923077   \n",
              "17           0.769231           1.000000           1.000000   \n",
              "18           0.769231           1.000000           0.923077   \n",
              "19           0.769231           0.923077           0.923077   \n",
              "20           0.769231           1.000000           0.923077   \n",
              "21           0.769231           1.000000           1.000000   \n",
              "22           0.769231           1.000000           0.923077   \n",
              "23           0.769231           0.923077           1.000000   \n",
              "24           0.769231           1.000000           0.923077   \n",
              "25           0.769231           0.923077           0.923077   \n",
              "26           0.769231           1.000000           1.000000   \n",
              "27           0.769231           1.000000           0.923077   \n",
              "28           0.769231           1.000000           0.923077   \n",
              "29           0.769231           0.923077           0.923077   \n",
              "30           0.769231           0.923077           0.923077   \n",
              "31           0.769231           0.923077           0.923077   \n",
              "32           0.769231           1.000000           1.000000   \n",
              "33           0.769231           1.000000           1.000000   \n",
              "34           0.769231           0.923077           0.923077   \n",
              "35           0.769231           1.000000           0.923077   \n",
              "\n",
              "    split4_test_score  split5_test_score  split6_test_score  \\\n",
              "0            0.923077           0.846154               0.75   \n",
              "1            0.923077           0.769231               0.75   \n",
              "2            0.923077           0.769231               0.75   \n",
              "3            0.923077           0.769231               0.75   \n",
              "4            0.923077           0.769231               0.75   \n",
              "5            0.923077           0.846154               0.75   \n",
              "6            0.923077           0.846154               0.75   \n",
              "7            0.923077           0.846154               0.75   \n",
              "8            0.923077           0.769231               0.75   \n",
              "9            0.923077           0.769231               0.75   \n",
              "10           0.923077           0.769231               0.75   \n",
              "11           0.923077           0.769231               0.75   \n",
              "12           0.846154           0.769231               0.75   \n",
              "13           0.923077           0.846154               0.75   \n",
              "14           0.923077           0.769231               0.75   \n",
              "15           0.923077           0.769231               0.75   \n",
              "16           0.846154           0.769231               0.75   \n",
              "17           0.923077           0.769231               0.75   \n",
              "18           0.923077           0.846154               0.75   \n",
              "19           0.923077           0.769231               0.75   \n",
              "20           0.923077           0.846154               0.75   \n",
              "21           0.923077           0.769231               0.75   \n",
              "22           0.923077           0.769231               0.75   \n",
              "23           0.846154           0.769231               0.75   \n",
              "24           0.846154           0.769231               0.75   \n",
              "25           0.846154           0.769231               0.75   \n",
              "26           0.923077           0.846154               0.75   \n",
              "27           0.923077           0.769231               0.75   \n",
              "28           0.923077           0.769231               0.75   \n",
              "29           0.923077           0.769231               0.75   \n",
              "30           0.923077           0.769231               0.75   \n",
              "31           0.923077           0.769231               0.75   \n",
              "32           0.846154           0.769231               0.75   \n",
              "33           0.923077           0.769231               0.75   \n",
              "34           0.923077           0.846154               0.75   \n",
              "35           0.923077           0.769231               0.75   \n",
              "\n",
              "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
              "0            0.916667           1.000000           0.833333         0.873077   \n",
              "1            0.916667           1.000000           0.833333         0.880769   \n",
              "2            0.916667           1.000000           0.750000         0.864744   \n",
              "3            0.916667           1.000000           0.833333         0.880769   \n",
              "4            0.916667           1.000000           0.833333         0.880769   \n",
              "5            0.916667           1.000000           0.750000         0.880128   \n",
              "6            0.916667           1.000000           0.750000         0.872436   \n",
              "7            0.916667           0.916667           0.833333         0.864744   \n",
              "8            0.916667           1.000000           0.833333         0.873077   \n",
              "9            0.916667           0.916667           0.833333         0.872436   \n",
              "10           0.916667           1.000000           0.833333         0.873077   \n",
              "11           0.916667           1.000000           0.750000         0.864744   \n",
              "12           0.916667           1.000000           0.750000         0.857051   \n",
              "13           0.916667           1.000000           0.833333         0.865385   \n",
              "14           0.916667           1.000000           0.750000         0.864744   \n",
              "15           0.916667           1.000000           0.833333         0.865385   \n",
              "16           0.916667           1.000000           0.833333         0.865385   \n",
              "17           0.916667           1.000000           0.833333         0.880769   \n",
              "18           0.916667           0.916667           0.833333         0.872436   \n",
              "19           0.916667           1.000000           0.750000         0.857051   \n",
              "20           0.916667           1.000000           0.833333         0.880769   \n",
              "21           0.916667           1.000000           0.750000         0.872436   \n",
              "22           0.916667           1.000000           0.833333         0.873077   \n",
              "23           0.916667           1.000000           0.750000         0.857051   \n",
              "24           0.916667           1.000000           0.833333         0.865385   \n",
              "25           0.916667           1.000000           0.833333         0.865385   \n",
              "26           0.916667           1.000000           0.833333         0.888462   \n",
              "27           0.916667           1.000000           0.833333         0.873077   \n",
              "28           0.916667           1.000000           0.833333         0.873077   \n",
              "29           0.916667           1.000000           0.750000         0.857051   \n",
              "30           0.916667           1.000000           0.750000         0.857051   \n",
              "31           0.916667           1.000000           0.750000         0.864744   \n",
              "32           0.916667           1.000000           0.750000         0.864744   \n",
              "33           0.916667           1.000000           0.833333         0.888462   \n",
              "34           0.916667           1.000000           0.750000         0.864744   \n",
              "35           0.916667           1.000000           0.750000         0.864744   \n",
              "\n",
              "    std_test_score  rank_test_score  \n",
              "0         0.073804                9  \n",
              "1         0.095476                3  \n",
              "2         0.095401               24  \n",
              "3         0.089063                3  \n",
              "4         0.095476                3  \n",
              "5         0.091064                8  \n",
              "6         0.083552               15  \n",
              "7         0.079521               24  \n",
              "8         0.088396                9  \n",
              "9         0.081056               15  \n",
              "10        0.088396                9  \n",
              "11        0.095401               24  \n",
              "12        0.086908               32  \n",
              "13        0.072183               22  \n",
              "14        0.095401               24  \n",
              "15        0.079961               19  \n",
              "16        0.079961               19  \n",
              "17        0.095476                3  \n",
              "18        0.073394               15  \n",
              "19        0.086908               32  \n",
              "20        0.082151                3  \n",
              "21        0.102622               15  \n",
              "22        0.088396                9  \n",
              "23        0.093469               32  \n",
              "24        0.087047               22  \n",
              "25        0.079961               19  \n",
              "26        0.089063                1  \n",
              "27        0.088396                9  \n",
              "28        0.088396                9  \n",
              "29        0.086908               32  \n",
              "30        0.086908               32  \n",
              "31        0.088983               24  \n",
              "32        0.101414               24  \n",
              "33        0.095476                1  \n",
              "34        0.082064               24  \n",
              "35        0.095401               24  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-149c9ae7-32a0-467b-aebc-eab18bae0d76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.591937</td>\n",
              "      <td>0.017445</td>\n",
              "      <td>0.046260</td>\n",
              "      <td>0.005457</td>\n",
              "      <td>7</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 250}</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.073804</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.699852</td>\n",
              "      <td>0.017520</td>\n",
              "      <td>0.052870</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>7</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 300}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880769</td>\n",
              "      <td>0.095476</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.810102</td>\n",
              "      <td>0.011763</td>\n",
              "      <td>0.063593</td>\n",
              "      <td>0.005858</td>\n",
              "      <td>7</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.095401</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.935931</td>\n",
              "      <td>0.011581</td>\n",
              "      <td>0.070276</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>7</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 400}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880769</td>\n",
              "      <td>0.089063</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.042114</td>\n",
              "      <td>0.012556</td>\n",
              "      <td>0.079592</td>\n",
              "      <td>0.005098</td>\n",
              "      <td>7</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 450}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880769</td>\n",
              "      <td>0.095476</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.159430</td>\n",
              "      <td>0.015995</td>\n",
              "      <td>0.087570</td>\n",
              "      <td>0.002998</td>\n",
              "      <td>7</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 7, 'n_estimators': 500}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.880128</td>\n",
              "      <td>0.091064</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.586941</td>\n",
              "      <td>0.010723</td>\n",
              "      <td>0.044078</td>\n",
              "      <td>0.001365</td>\n",
              "      <td>8</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 250}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.872436</td>\n",
              "      <td>0.083552</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.714026</td>\n",
              "      <td>0.021589</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>8</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 300}</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.079521</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.830452</td>\n",
              "      <td>0.011814</td>\n",
              "      <td>0.066262</td>\n",
              "      <td>0.011771</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.088396</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.950566</td>\n",
              "      <td>0.021602</td>\n",
              "      <td>0.069221</td>\n",
              "      <td>0.002092</td>\n",
              "      <td>8</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 400}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.872436</td>\n",
              "      <td>0.081056</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.057002</td>\n",
              "      <td>0.013511</td>\n",
              "      <td>0.077877</td>\n",
              "      <td>0.002779</td>\n",
              "      <td>8</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 450}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.088396</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.175970</td>\n",
              "      <td>0.015584</td>\n",
              "      <td>0.087078</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>8</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 8, 'n_estimators': 500}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.095401</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.598533</td>\n",
              "      <td>0.012657</td>\n",
              "      <td>0.046022</td>\n",
              "      <td>0.006510</td>\n",
              "      <td>9</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 250}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857051</td>\n",
              "      <td>0.086908</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.717412</td>\n",
              "      <td>0.018444</td>\n",
              "      <td>0.053233</td>\n",
              "      <td>0.005345</td>\n",
              "      <td>9</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 300}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.072183</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.840146</td>\n",
              "      <td>0.017874</td>\n",
              "      <td>0.059204</td>\n",
              "      <td>0.001202</td>\n",
              "      <td>9</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.095401</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.952790</td>\n",
              "      <td>0.015310</td>\n",
              "      <td>0.067231</td>\n",
              "      <td>0.000706</td>\n",
              "      <td>9</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 400}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.073415</td>\n",
              "      <td>0.025781</td>\n",
              "      <td>0.084002</td>\n",
              "      <td>0.016585</td>\n",
              "      <td>9</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 450}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.201793</td>\n",
              "      <td>0.029176</td>\n",
              "      <td>0.084818</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>9</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 9, 'n_estimators': 500}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880769</td>\n",
              "      <td>0.095476</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.604089</td>\n",
              "      <td>0.011328</td>\n",
              "      <td>0.045774</td>\n",
              "      <td>0.006544</td>\n",
              "      <td>10</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 250}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.872436</td>\n",
              "      <td>0.073394</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.725539</td>\n",
              "      <td>0.011654</td>\n",
              "      <td>0.051192</td>\n",
              "      <td>0.002337</td>\n",
              "      <td>10</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 300}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857051</td>\n",
              "      <td>0.086908</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.849230</td>\n",
              "      <td>0.012535</td>\n",
              "      <td>0.060575</td>\n",
              "      <td>0.005969</td>\n",
              "      <td>10</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.880769</td>\n",
              "      <td>0.082151</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.968342</td>\n",
              "      <td>0.014383</td>\n",
              "      <td>0.068884</td>\n",
              "      <td>0.002275</td>\n",
              "      <td>10</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 400}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.872436</td>\n",
              "      <td>0.102622</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.092851</td>\n",
              "      <td>0.019991</td>\n",
              "      <td>0.076586</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>10</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 450}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.088396</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.208295</td>\n",
              "      <td>0.023697</td>\n",
              "      <td>0.085552</td>\n",
              "      <td>0.003687</td>\n",
              "      <td>10</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 10, 'n_estimators': 500}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857051</td>\n",
              "      <td>0.093469</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.626611</td>\n",
              "      <td>0.012661</td>\n",
              "      <td>0.044301</td>\n",
              "      <td>0.002368</td>\n",
              "      <td>12</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 250}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.087047</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.737643</td>\n",
              "      <td>0.010097</td>\n",
              "      <td>0.055498</td>\n",
              "      <td>0.007288</td>\n",
              "      <td>12</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 300}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.079961</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.874947</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.061748</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>12</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.888462</td>\n",
              "      <td>0.089063</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.981211</td>\n",
              "      <td>0.009460</td>\n",
              "      <td>0.067340</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>12</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 400}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.088396</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.115720</td>\n",
              "      <td>0.020121</td>\n",
              "      <td>0.075922</td>\n",
              "      <td>0.001822</td>\n",
              "      <td>12</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 450}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.088396</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.231444</td>\n",
              "      <td>0.012711</td>\n",
              "      <td>0.085046</td>\n",
              "      <td>0.002589</td>\n",
              "      <td>12</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 12, 'n_estimators': 500}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857051</td>\n",
              "      <td>0.086908</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.630603</td>\n",
              "      <td>0.009662</td>\n",
              "      <td>0.042459</td>\n",
              "      <td>0.001643</td>\n",
              "      <td>13</td>\n",
              "      <td>250</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 250}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857051</td>\n",
              "      <td>0.086908</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.752881</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.050644</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>13</td>\n",
              "      <td>300</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 300}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.088983</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.882052</td>\n",
              "      <td>0.015311</td>\n",
              "      <td>0.058209</td>\n",
              "      <td>0.001247</td>\n",
              "      <td>13</td>\n",
              "      <td>350</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 350}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.101414</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.012536</td>\n",
              "      <td>0.018729</td>\n",
              "      <td>0.069874</td>\n",
              "      <td>0.004926</td>\n",
              "      <td>13</td>\n",
              "      <td>400</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 400}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.888462</td>\n",
              "      <td>0.095476</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1.584637</td>\n",
              "      <td>0.402313</td>\n",
              "      <td>0.097955</td>\n",
              "      <td>0.030593</td>\n",
              "      <td>13</td>\n",
              "      <td>450</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 450}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.082064</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.249749</td>\n",
              "      <td>0.027702</td>\n",
              "      <td>0.085544</td>\n",
              "      <td>0.017387</td>\n",
              "      <td>13</td>\n",
              "      <td>500</td>\n",
              "      <td>{'max_features': 13, 'n_estimators': 500}</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>0.095401</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-149c9ae7-32a0-467b-aebc-eab18bae0d76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-149c9ae7-32a0-467b-aebc-eab18bae0d76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-149c9ae7-32a0-467b-aebc-eab18bae0d76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_Forest Classifies: ***** \n",
            "Best Accuracy: 88.85 %\n",
            "Best Parameters: {'max_features': 12, 'n_estimators': 350}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7Z9-Z1n877B"
      },
      "id": "x7Z9-Z1n877B",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "40b7c102bcf05e5897256ca18f96aa7dd41cd47c950cbadcdc11647e772909c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}